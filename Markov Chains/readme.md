[BACK TO MAIN](https://github.com/TracyChacon)


# Markov Chains using Python (Code may be provided upon request)
## Overview
While researching how to fix a missing head issue in git, I was presented with a challenge from Google. The challenge was to solve a problem but there was no mention of using Markov chains, a type of mathematical model that can be used to predict future states based on current states. I had never heard of Markov chains before, but I was intrigued by the challenge and decided to give it a try.

I spent several hours learning about Markov chains and how they can be used to solve problems. I also researched the Google foobar challenge and found that it was a series of challenges designed to test the skills of potential Google employees. I was determined to solve the challenge, so I put my newfound knowledge of Markov chains to work.

After a lot of trial and error, I was able to develop a Python function that could solve the problem. I was very happy with my solution, and I was even more excited to learn that I had passed the challenge. I had never come across Markov chains before, but I was now a convert. I found the topic to be fascinating, and I was eager to learn more about it.

I am grateful to Google for the challenge. It was a challenging but rewarding experience that taught me a lot about Markov chains and problem-solving. I am now a better engineer because of it.

## Code Assessment 
The function 
- identifies unreachable and terminal reachable states in the matrix.
- normalizes the probabilities in the matrix so that they sum to 1.
- calculates the probability of reaching all states by raising the normalized matrix to a power.
The code uses the following Python libraries:

#### Libraries Used
- decimal - This library is used to work with decimal numbers.
- math - This library is used to calculate mathematical functions, such as the power function.

The code can be improved by adding the following features:

- Could be made more efficient by using a different matrix multiplication algorithm.
- Could be made more user-friendly by adding error handling and input validation.
- Could be made more versatile by allowing the user to specify the number of times the matrix is raised to a power.

Overall, the code is well-written and easy to understand. It is a good example of how to calculate the probability of reaching all states in a Markov chain.

## Use cases:
### Markov property: 
The Markov property states that the probability of a future state depends only on the current state, and not on any previous states. This means that the future is independent of the past.
### Stochasticity: 
Markov chains are stochastic, which means that the future is not predetermined. The probability of a future state can only be estimated, not known for certain.
### Discrete time: 
Markov chains are discrete-time, which means that the state of the system changes at discrete intervals. This means that the system cannot change its state instantaneously.

Markov chains are used to model a wide variety of phenomena, including:

### Natural phenomena:
The spread of a virus, the weather, and the stock market are all examples of natural phenomena that can be modeled by Markov chains.

### Human behavior:
The behavior of individuals and groups can also be modeled by Markov chains. For example, Markov chains can be used to model the choices that people make in games, the way that people learn, and the way that people spread information.

### Computer science:
Markov chains are used in computer science for a variety of purposes, including:

### Text generation:
Markov chains can be used to generate text that is similar to a given piece of text.

### Speech recognition: 
Markov chains can be used to recognize speech.

### Machine learning: 
Markov chains can be used to train machine learning models.
